<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="description" content="Image Matching: Local Features &amp; Beyond - CVPR 2019 Workshop">
<meta name="keywords" content="image,matching,local Features, CVPR 2019, Workshop, CVPR">

<base href="https://image-matching-workshop.github.io/">

<title>Image Matching: Local Features &amp; Beyond</title>

<meta name="generator" content="Hugo 0.53" />



<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/datatables.min.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/main.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/custom.css">




<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">





<script type="text/javascript" src="https://image-matching-workshop.github.io/js/jquery.latest.min.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/datatables.min.js"></script>
<script>
$(document).ready(function (){
    var table = $('.leaderboard_stereo').DataTable({
        "columnDefs": [{targets:[0, 2], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 3, 4, 5, 6, 7, 8, 9], orderSequence: ['desc', 'asc']}],
        "order": [[7, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td><b>'+col.title+':'+'</b></td> '+
                                '<td>'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    var table = $('.leaderboard_mvs').DataTable({
        "columnDefs": [{targets:[0, 2], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], orderSequence: ['desc', 'asc']}],
        "order": [[9, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td><b>'+col.title+':'+'</b></td> '+
                                '<td>'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    var table = $('.checkerboard').DataTable({
        "columnDefs": [{targets:[0], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], orderSequence: ['desc', 'asc']}],
        "order": [[12, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td><b>'+col.title+':'+'</b></td> '+
                                '<td>'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    $('.tablelist').dataTable({searching: false, paging: false, info: false});

    

    
    $('#btn-show-all-children').on('click', function(){
        
        table.rows(':not(.parent)').nodes().to$().find('td:first-child').trigger('click');
    });

    
    $('#btn-hide-all-children').on('click', function(){
        
        table.rows('.parent').nodes().to$().find('td:first-child').trigger('click');
    });
});
</script>
</head>
<body lang="en-US">
<div class="container">


<header class="row text-left title">
  <h1 class="title">Breakdown: Phototourism | Stereo | Sequences</h1>
</header>
<section id="category-pane" class="row meta">
  
</section>
<section id="content-pane" class="row">
  <div class="col-md-12 text-justify content">
    

<p>Breakdown on the Phototourism dataset, multi-view stereo task, by sequence.</p>

<hr>

<p>



<b>BM:</b> "british_museum" <b>FCS:</b> "florence_cathedral_side" <b>LMS:</b> "lincoln_memorial_statue" <b>LB:</b> "london_bridge" <b>MC:</b> "milan_cathedral" <b>MR:</b> "mount_rushmore" <b>PSM:</b> "piazza_san_marco" <b>RS:</b> "reichstag" <b>SF:</b> "sagrada_familia" <b>SPC:</b> "st_pauls_cathedral" <b>USC:</b> "united_states_capitol" <b>AVG:</b> average 
Sequence index:







<br />
<br />
<table class="display checkerboard" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">Stereo &mdash; All sequences &mdash; Sorted by mAP<sup>15<sup>o</sup></sup></th>
</tr>
<tr>
  
  <th class="all">Method</th>
  

  <th class="all">BM</th>

  <th class="all">FCS</th>

  <th class="all">LMS</th>

  <th class="all">LB</th>

  <th class="all">MC</th>

  <th class="all">MR</th>

  <th class="all">PSM</th>

  <th class="all">RS</th>

  <th class="all">SF</th>

  <th class="all">SPC</th>

  <th class="all">USC</th>

  <th class="all">AVG</th>

  
  <th class="none hidden_key">Date</th>
  <th class="none hidden_key">Type</th>
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>



<tr>
  
  <td>AKAZE (8k, NN)</td>






  <td>0.056</td>






  <td>0.013</td>






  <td>0.018</td>






  <td>0.057</td>






  <td>0.021</td>






  <td>0.011</td>






  <td>0.021</td>






  <td>0.033</td>






  <td>0.014</td>






  <td>0.010</td>






  <td>0.063</td>






  <td>0.029</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>ORB (8k, NN)</td>






  <td>0.050</td>






  <td>0.009</td>






  <td>0.007</td>






  <td>0.023</td>






  <td>0.011</td>






  <td>0.007</td>






  <td>0.016</td>






  <td>0.032</td>






  <td>0.010</td>






  <td>0.008</td>






  <td>0.034</td>






  <td>0.019</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>GeoDesc (8k, NN)</td>






  <td>0.075</td>






  <td>0.026</td>






  <td>0.039</td>






  <td>0.046</td>






  <td>0.039</td>






  <td>0.018</td>






  <td>0.024</td>






  <td>0.043</td>






  <td>0.032</td>






  <td>0.016</td>






  <td>0.046</td>






  <td>0.037</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>HardNet (8k, NN)</td>






  <td>0.081</td>






  <td>0.029</td>






  <td>0.061</td>






  <td>0.048</td>






  <td>0.054</td>






  <td>0.020</td>






  <td>0.024</td>






  <td>0.049</td>






  <td>0.040</td>






  <td>0.020</td>






  <td>0.041</td>






  <td>0.043</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>L2-Net (8k, NN)</td>






  <td>0.083</td>






  <td>0.027</td>






  <td>0.044</td>






  <td>0.044</td>






  <td>0.046</td>






  <td>0.022</td>






  <td>0.024</td>






  <td>0.049</td>






  <td>0.039</td>






  <td>0.020</td>






  <td>0.043</td>






  <td>0.040</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>SIFT (8k, NN)</td>






  <td>0.055</td>






  <td>0.016</td>






  <td>0.017</td>






  <td>0.041</td>






  <td>0.023</td>






  <td>0.016</td>






  <td>0.020</td>






  <td>0.040</td>






  <td>0.016</td>






  <td>0.011</td>






  <td>0.050</td>






  <td>0.028</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>TFeat (8k, NN)</td>






  <td>0.074</td>






  <td>0.025</td>






  <td>0.033</td>






  <td>0.049</td>






  <td>0.042</td>






  <td>0.019</td>






  <td>0.022</td>






  <td>0.047</td>






  <td>0.027</td>






  <td>0.016</td>






  <td>0.038</td>






  <td>0.036</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>SuperPoint</td>






  <td>0.080</td>






  <td>0.030</td>






  <td>0.054</td>






  <td>0.078</td>






  <td>0.040</td>






  <td>0.013</td>






  <td>0.029</td>






  <td>0.048</td>






  <td>0.035</td>






  <td>0.017</td>






  <td>0.031</td>






  <td>0.041</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>SURF (8k, NN)</td>






  <td>0.044</td>






  <td>0.009</td>






  <td>0.014</td>






  <td>0.027</td>






  <td>0.021</td>






  <td>0.011</td>






  <td>0.020</td>






  <td>0.035</td>






  <td>0.009</td>






  <td>0.007</td>






  <td>0.036</td>






  <td>0.021</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;british_museum&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7963.6</td>
  <td>0.228</td>
  <td>0.002</td>
  <td>0.018</td>
  <td>0.056</td>
  <td>0.107</td>
  <td>0.162</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7494.1</td>
  <td>0.221</td>
  <td>0.001</td>
  <td>0.016</td>
  <td>0.050</td>
  <td>0.097</td>
  <td>0.156</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7968.5</td>
  <td>0.229</td>
  <td>0.002</td>
  <td>0.030</td>
  <td>0.075</td>
  <td>0.124</td>
  <td>0.180</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7968.5</td>
  <td>0.259</td>
  <td>0.002</td>
  <td>0.029</td>
  <td>0.081</td>
  <td>0.137</td>
  <td>0.196</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7968.5</td>
  <td>0.247</td>
  <td>0.003</td>
  <td>0.032</td>
  <td>0.083</td>
  <td>0.134</td>
  <td>0.191</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7968.3</td>
  <td>0.200</td>
  <td>0.002</td>
  <td>0.018</td>
  <td>0.055</td>
  <td>0.098</td>
  <td>0.143</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7968.5</td>
  <td>0.232</td>
  <td>0.002</td>
  <td>0.031</td>
  <td>0.074</td>
  <td>0.132</td>
  <td>0.188</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1156.4</td>
  <td>0.267</td>
  <td>0.001</td>
  <td>0.031</td>
  <td>0.080</td>
  <td>0.154</td>
  <td>0.222</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7830.3</td>
  <td>0.201</td>
  <td>0.001</td>
  <td>0.016</td>
  <td>0.044</td>
  <td>0.087</td>
  <td>0.134</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;florence_cathedral_side&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7859.0</td>
  <td>0.160</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.013</td>
  <td>0.029</td>
  <td>0.056</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7886.4</td>
  <td>0.164</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.009</td>
  <td>0.020</td>
  <td>0.040</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7874.2</td>
  <td>0.188</td>
  <td>0.000</td>
  <td>0.007</td>
  <td>0.026</td>
  <td>0.065</td>
  <td>0.127</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7874.2</td>
  <td>0.202</td>
  <td>0.001</td>
  <td>0.007</td>
  <td>0.029</td>
  <td>0.073</td>
  <td>0.142</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7874.2</td>
  <td>0.199</td>
  <td>0.001</td>
  <td>0.008</td>
  <td>0.027</td>
  <td>0.065</td>
  <td>0.132</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7873.7</td>
  <td>0.175</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.016</td>
  <td>0.037</td>
  <td>0.084</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7874.2</td>
  <td>0.188</td>
  <td>0.000</td>
  <td>0.009</td>
  <td>0.025</td>
  <td>0.058</td>
  <td>0.116</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1663.1</td>
  <td>0.202</td>
  <td>0.001</td>
  <td>0.008</td>
  <td>0.030</td>
  <td>0.065</td>
  <td>0.135</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7830.2</td>
  <td>0.163</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.009</td>
  <td>0.025</td>
  <td>0.054</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;lincoln_memorial_statue&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7799.0</td>
  <td>0.283</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.018</td>
  <td>0.051</td>
  <td>0.110</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>3920.7</td>
  <td>0.316</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.007</td>
  <td>0.020</td>
  <td>0.038</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7771.0</td>
  <td>0.288</td>
  <td>0.001</td>
  <td>0.009</td>
  <td>0.039</td>
  <td>0.097</td>
  <td>0.185</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7771.0</td>
  <td>0.303</td>
  <td>0.001</td>
  <td>0.015</td>
  <td>0.061</td>
  <td>0.143</td>
  <td>0.248</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7771.0</td>
  <td>0.300</td>
  <td>0.001</td>
  <td>0.012</td>
  <td>0.044</td>
  <td>0.126</td>
  <td>0.224</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7770.9</td>
  <td>0.268</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.017</td>
  <td>0.046</td>
  <td>0.103</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7771.0</td>
  <td>0.291</td>
  <td>0.000</td>
  <td>0.008</td>
  <td>0.033</td>
  <td>0.088</td>
  <td>0.174</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>808.2</td>
  <td>0.336</td>
  <td>0.002</td>
  <td>0.018</td>
  <td>0.054</td>
  <td>0.129</td>
  <td>0.208</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7723.4</td>
  <td>0.262</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.014</td>
  <td>0.040</td>
  <td>0.081</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;london_bridge&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7962.8</td>
  <td>0.255</td>
  <td>0.000</td>
  <td>0.007</td>
  <td>0.057</td>
  <td>0.147</td>
  <td>0.247</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>6982.2</td>
  <td>0.241</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.023</td>
  <td>0.077</td>
  <td>0.146</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7955.7</td>
  <td>0.269</td>
  <td>0.000</td>
  <td>0.006</td>
  <td>0.046</td>
  <td>0.123</td>
  <td>0.216</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7955.7</td>
  <td>0.291</td>
  <td>0.000</td>
  <td>0.009</td>
  <td>0.048</td>
  <td>0.127</td>
  <td>0.203</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7955.7</td>
  <td>0.291</td>
  <td>0.000</td>
  <td>0.007</td>
  <td>0.044</td>
  <td>0.108</td>
  <td>0.192</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7954.4</td>
  <td>0.251</td>
  <td>0.000</td>
  <td>0.007</td>
  <td>0.041</td>
  <td>0.108</td>
  <td>0.198</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7955.7</td>
  <td>0.277</td>
  <td>0.000</td>
  <td>0.008</td>
  <td>0.049</td>
  <td>0.114</td>
  <td>0.190</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1094.0</td>
  <td>0.289</td>
  <td>0.000</td>
  <td>0.014</td>
  <td>0.078</td>
  <td>0.184</td>
  <td>0.276</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7915.0</td>
  <td>0.246</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.027</td>
  <td>0.077</td>
  <td>0.150</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;milan_cathedral&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7818.1</td>
  <td>0.184</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.021</td>
  <td>0.057</td>
  <td>0.126</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7653.5</td>
  <td>0.173</td>
  <td>0.000</td>
  <td>0.001</td>
  <td>0.011</td>
  <td>0.034</td>
  <td>0.070</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7823.6</td>
  <td>0.195</td>
  <td>0.000</td>
  <td>0.009</td>
  <td>0.039</td>
  <td>0.108</td>
  <td>0.201</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7823.6</td>
  <td>0.209</td>
  <td>0.001</td>
  <td>0.010</td>
  <td>0.054</td>
  <td>0.127</td>
  <td>0.225</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7823.6</td>
  <td>0.206</td>
  <td>0.002</td>
  <td>0.010</td>
  <td>0.046</td>
  <td>0.115</td>
  <td>0.211</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7823.8</td>
  <td>0.181</td>
  <td>0.000</td>
  <td>0.006</td>
  <td>0.023</td>
  <td>0.074</td>
  <td>0.147</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7823.6</td>
  <td>0.196</td>
  <td>0.001</td>
  <td>0.011</td>
  <td>0.042</td>
  <td>0.100</td>
  <td>0.188</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1483.6</td>
  <td>0.208</td>
  <td>0.001</td>
  <td>0.009</td>
  <td>0.040</td>
  <td>0.106</td>
  <td>0.194</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7630.6</td>
  <td>0.170</td>
  <td>0.001</td>
  <td>0.005</td>
  <td>0.021</td>
  <td>0.053</td>
  <td>0.107</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;mount_rushmore&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7809.6</td>
  <td>0.360</td>
  <td>0.000</td>
  <td>0.001</td>
  <td>0.011</td>
  <td>0.055</td>
  <td>0.148</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7279.8</td>
  <td>0.382</td>
  <td>0.000</td>
  <td>0.000</td>
  <td>0.007</td>
  <td>0.045</td>
  <td>0.107</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7791.0</td>
  <td>0.371</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.018</td>
  <td>0.085</td>
  <td>0.186</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7791.0</td>
  <td>0.393</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.020</td>
  <td>0.083</td>
  <td>0.189</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7791.0</td>
  <td>0.389</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.022</td>
  <td>0.078</td>
  <td>0.179</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7788.9</td>
  <td>0.356</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.016</td>
  <td>0.070</td>
  <td>0.157</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7791.0</td>
  <td>0.379</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.019</td>
  <td>0.078</td>
  <td>0.170</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>936.8</td>
  <td>0.377</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.013</td>
  <td>0.045</td>
  <td>0.104</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7514.8</td>
  <td>0.350</td>
  <td>0.000</td>
  <td>0.001</td>
  <td>0.011</td>
  <td>0.051</td>
  <td>0.119</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;piazza_san_marco&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7783.7</td>
  <td>0.156</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.021</td>
  <td>0.066</td>
  <td>0.133</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7816.3</td>
  <td>0.167</td>
  <td>0.000</td>
  <td>0.001</td>
  <td>0.016</td>
  <td>0.060</td>
  <td>0.129</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7808.0</td>
  <td>0.164</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.024</td>
  <td>0.081</td>
  <td>0.159</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7808.0</td>
  <td>0.174</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.024</td>
  <td>0.084</td>
  <td>0.171</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7808.0</td>
  <td>0.170</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.024</td>
  <td>0.081</td>
  <td>0.168</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7807.2</td>
  <td>0.154</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.020</td>
  <td>0.065</td>
  <td>0.129</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7808.0</td>
  <td>0.164</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.022</td>
  <td>0.077</td>
  <td>0.155</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1557.9</td>
  <td>0.168</td>
  <td>0.000</td>
  <td>0.006</td>
  <td>0.029</td>
  <td>0.086</td>
  <td>0.172</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7680.7</td>
  <td>0.146</td>
  <td>0.001</td>
  <td>0.005</td>
  <td>0.020</td>
  <td>0.059</td>
  <td>0.128</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;reichstag&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7961.9</td>
  <td>0.262</td>
  <td>0.001</td>
  <td>0.007</td>
  <td>0.033</td>
  <td>0.081</td>
  <td>0.159</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7094.3</td>
  <td>0.273</td>
  <td>0.000</td>
  <td>0.010</td>
  <td>0.032</td>
  <td>0.079</td>
  <td>0.147</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7977.9</td>
  <td>0.304</td>
  <td>0.000</td>
  <td>0.013</td>
  <td>0.043</td>
  <td>0.096</td>
  <td>0.171</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7977.9</td>
  <td>0.352</td>
  <td>0.002</td>
  <td>0.016</td>
  <td>0.049</td>
  <td>0.108</td>
  <td>0.185</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7977.9</td>
  <td>0.339</td>
  <td>0.001</td>
  <td>0.015</td>
  <td>0.049</td>
  <td>0.092</td>
  <td>0.175</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7978.0</td>
  <td>0.261</td>
  <td>0.000</td>
  <td>0.009</td>
  <td>0.040</td>
  <td>0.086</td>
  <td>0.155</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7977.9</td>
  <td>0.311</td>
  <td>0.002</td>
  <td>0.015</td>
  <td>0.047</td>
  <td>0.093</td>
  <td>0.167</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1226.4</td>
  <td>0.380</td>
  <td>0.001</td>
  <td>0.019</td>
  <td>0.048</td>
  <td>0.097</td>
  <td>0.170</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7719.0</td>
  <td>0.239</td>
  <td>0.000</td>
  <td>0.009</td>
  <td>0.035</td>
  <td>0.067</td>
  <td>0.131</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;sagrada_familia&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7862.3</td>
  <td>0.143</td>
  <td>0.001</td>
  <td>0.006</td>
  <td>0.014</td>
  <td>0.030</td>
  <td>0.054</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7643.7</td>
  <td>0.142</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.010</td>
  <td>0.020</td>
  <td>0.034</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7896.1</td>
  <td>0.152</td>
  <td>0.001</td>
  <td>0.011</td>
  <td>0.032</td>
  <td>0.072</td>
  <td>0.122</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7896.1</td>
  <td>0.163</td>
  <td>0.001</td>
  <td>0.013</td>
  <td>0.040</td>
  <td>0.084</td>
  <td>0.143</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7896.1</td>
  <td>0.159</td>
  <td>0.001</td>
  <td>0.010</td>
  <td>0.039</td>
  <td>0.079</td>
  <td>0.128</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7894.1</td>
  <td>0.138</td>
  <td>0.000</td>
  <td>0.004</td>
  <td>0.016</td>
  <td>0.034</td>
  <td>0.058</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7896.1</td>
  <td>0.152</td>
  <td>0.001</td>
  <td>0.009</td>
  <td>0.027</td>
  <td>0.057</td>
  <td>0.095</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1474.5</td>
  <td>0.171</td>
  <td>0.001</td>
  <td>0.011</td>
  <td>0.035</td>
  <td>0.074</td>
  <td>0.125</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7732.5</td>
  <td>0.139</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.009</td>
  <td>0.024</td>
  <td>0.041</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;st_pauls_cathedral&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7857.2</td>
  <td>0.151</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.010</td>
  <td>0.029</td>
  <td>0.065</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7683.3</td>
  <td>0.141</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.008</td>
  <td>0.020</td>
  <td>0.037</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7869.2</td>
  <td>0.156</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.016</td>
  <td>0.044</td>
  <td>0.096</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7869.2</td>
  <td>0.169</td>
  <td>0.001</td>
  <td>0.005</td>
  <td>0.020</td>
  <td>0.053</td>
  <td>0.106</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7869.2</td>
  <td>0.165</td>
  <td>0.000</td>
  <td>0.005</td>
  <td>0.020</td>
  <td>0.051</td>
  <td>0.100</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7868.9</td>
  <td>0.145</td>
  <td>0.000</td>
  <td>0.003</td>
  <td>0.011</td>
  <td>0.031</td>
  <td>0.068</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7869.2</td>
  <td>0.157</td>
  <td>0.001</td>
  <td>0.004</td>
  <td>0.016</td>
  <td>0.045</td>
  <td>0.087</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1371.5</td>
  <td>0.166</td>
  <td>0.001</td>
  <td>0.006</td>
  <td>0.017</td>
  <td>0.055</td>
  <td>0.102</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7714.1</td>
  <td>0.140</td>
  <td>0.000</td>
  <td>0.002</td>
  <td>0.007</td>
  <td>0.022</td>
  <td>0.053</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>




<table class="display leaderboard_stereo" cellspacing="0" width="100%">
<thead>
<tr>
  <th colspan="10" style="text-align: center;" class="sorter-false">Stereo &mdash; sequence &#39;united_states_capitol&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">#Kp</th>
  <th class="all">MS</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>


















<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>8000.0</td>
  <td>0.244</td>
  <td>0.003</td>
  <td>0.020</td>
  <td>0.063</td>
  <td>0.146</td>
  <td>0.259</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>6953.4</td>
  <td>0.243</td>
  <td>0.001</td>
  <td>0.008</td>
  <td>0.034</td>
  <td>0.080</td>
  <td>0.143</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>8000.0</td>
  <td>0.247</td>
  <td>0.002</td>
  <td>0.015</td>
  <td>0.046</td>
  <td>0.102</td>
  <td>0.176</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>8000.0</td>
  <td>0.260</td>
  <td>0.001</td>
  <td>0.012</td>
  <td>0.041</td>
  <td>0.087</td>
  <td>0.165</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>8000.0</td>
  <td>0.258</td>
  <td>0.001</td>
  <td>0.013</td>
  <td>0.043</td>
  <td>0.095</td>
  <td>0.165</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>8000.0</td>
  <td>0.235</td>
  <td>0.001</td>
  <td>0.015</td>
  <td>0.050</td>
  <td>0.111</td>
  <td>0.192</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>8000.0</td>
  <td>0.248</td>
  <td>0.001</td>
  <td>0.012</td>
  <td>0.038</td>
  <td>0.087</td>
  <td>0.164</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>1159.0</td>
  <td>0.272</td>
  <td>0.001</td>
  <td>0.009</td>
  <td>0.031</td>
  <td>0.071</td>
  <td>0.137</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork">https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>



















<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>7945.9</td>
  <td>0.229</td>
  <td>0.002</td>
  <td>0.011</td>
  <td>0.036</td>
  <td>0.090</td>
  <td>0.166</td>
 
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>


</p>

<h3 id="a-name-glossary-a-glossary"><a name="glossary"></a>Glossary</h3>

Stereo task:

<ul>
  <li><b>Type:</b> Input format. "F": Features. "M": Features and matches. "P": Poses.</li>
  <li><b>#Kp:</b> Average number of keypoints extracted.</li>
  <li><b>MS:</b> Matching Score.</li>
  <li><b>mAP<sup>x</sup>:</b> Mean average precision at angular threshold *x*.</li>
</ul>


  </div>
</section>
<section id="tag-pane" class="row meta">
  
</section>








<section id="menu-pane" class="row menu text-center">
  
  
  
  <span><a class="menu-item" href="/breakdown">breakdown</a></span>
  
  
  <span><a class="menu-item" href="https://image-matching-workshop.github.io/breakdown/phototourism/mvs/by_bag/"> | next &gt;</a></span>
  
  
  <h4 class="text-center"><a class="menu-item" href="https://image-matching-workshop.github.io/">home</a></h4>
</section>



<footer class="row text-center footer">
  
  
</footer>

</div>




<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-62863910-6', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="js/main.js"></script>

</script>
</body>
</html>


