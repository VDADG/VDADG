<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="description" content="Image Matching: Local Features &amp; Beyond - CVPR 2019 Workshop">
<meta name="keywords" content="image,matching,local Features, CVPR 2019, Workshop, CVPR">

<base href="https://image-matching-workshop.github.io/">

<title>Image Matching: Local Features &amp; Beyond</title>

<meta name="generator" content="Hugo 0.53" />



<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/datatables.min.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/main.css">
<link rel="stylesheet" href="https://image-matching-workshop.github.io/css/custom.css">




<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">





<script type="text/javascript" src="https://image-matching-workshop.github.io/js/jquery.latest.min.js"></script>
<script type="text/javascript" src="https://image-matching-workshop.github.io/js/datatables.min.js"></script>
<script>
$(document).ready(function (){
    var table = $('.leaderboard_stereo').DataTable({
        "columnDefs": [{targets:[0, 2], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 3, 4, 5, 6, 7, 8, 9], orderSequence: ['desc', 'asc']}],
        "order": [[7, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td><b>'+col.title+':'+'</b></td> '+
                                '<td>'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    var table = $('.leaderboard_mvs').DataTable({
        "columnDefs": [{targets:[0, 2], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 3, 4, 5, 6, 7, 8, 9, 10, 11], orderSequence: ['desc', 'asc']}],
        "order": [[9, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td><b>'+col.title+':'+'</b></td> '+
                                '<td>'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    var table = $('.checkerboard').DataTable({
        "columnDefs": [{targets:[0], orderSequence: ['desc', 'asc']}],
        "columnDefs": [{targets:[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], orderSequence: ['desc', 'asc']}],
        "order": [[12, 'desc']],
        responsive: {
            details: {
                renderer: function ( api, rowIdx, columns ) {
                    var data = $.map( columns, function ( col, i ) {
                        return col.hidden ?
                            '<tr data-dt-row="'+col.rowIndex+'" data-dt-column="'+col.columnIndex+'">'+
                                '<td><b>'+col.title+':'+'</b></td> '+
                                '<td>'+col.data+'</td>'+
                            '</tr>' :
                            '';
                    } ).join('');
 
                    return data ?
                        $('<table/>').append( data ) :
                        false;
                }
            }
        }
    });

    $('.tablelist').dataTable({searching: false, paging: false, info: false});

    

    
    $('#btn-show-all-children').on('click', function(){
        
        table.rows(':not(.parent)').nodes().to$().find('td:first-child').trigger('click');
    });

    
    $('#btn-hide-all-children').on('click', function(){
        
        table.rows('.parent').nodes().to$().find('td:first-child').trigger('click');
    });
});
</script>
</head>
<body lang="en-US">
<div class="container">


<header class="row text-left title">
  <h1 class="title">Breakdown: Phototourism | MVS | Sequences</h1>
</header>
<section id="category-pane" class="row meta">
  
</section>
<section id="content-pane" class="row">
  <div class="col-md-12 text-justify content">
    

<p>Breakdown on the Phototourism dataset, multi-view stereo task, by sequence.</p>

<hr>

<p>



<b>BM:</b> "british_museum" <b>FCS:</b> "florence_cathedral_side" <b>LMS:</b> "lincoln_memorial_statue" <b>LB:</b> "london_bridge" <b>MC:</b> "milan_cathedral" <b>MR:</b> "mount_rushmore" <b>PSM:</b> "piazza_san_marco" <b>RS:</b> "reichstag" <b>SF:</b> "sagrada_familia" <b>SPC:</b> "st_pauls_cathedral" <b>USC:</b> "united_states_capitol" <b>AVG:</b> average 











<br />
<br />
<table class="display checkerboard" width="100%">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; All sequences &mdash; Sorted by mAP<sup>15<sup>o</sup></sup></th>
</tr>
<tr>
  
  <th class="all">Method</th>
  

  <th class="all">BM</th>

  <th class="all">FCS</th>

  <th class="all">LMS</th>

  <th class="all">LB</th>

  <th class="all">MC</th>

  <th class="all">MR</th>

  <th class="all">PSM</th>

  <th class="all">RS</th>

  <th class="all">SF</th>

  <th class="all">SPC</th>

  <th class="all">USC</th>

  <th class="all">AVG</th>

  
  <th class="none hidden_key">Date</th>
  <th class="none hidden_key">Type</th>
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>



<tr>
  
  <td>AKAZE (8k, NN)</td>










  <td>0.358</td>










  <td>0.438</td>










  <td>0.555</td>










  <td>0.370</td>










  <td>0.594</td>










  <td>0.313</td>










  <td>0.254</td>










  <td>0.471</td>










  <td>0.571</td>










  <td>0.605</td>










  <td>0.185</td>










  <td>0.429</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>ORB (8k, NN)</td>










  <td>0.159</td>










  <td>0.306</td>










  <td>0.302</td>










  <td>0.164</td>










  <td>0.203</td>










  <td>0.140</td>










  <td>0.130</td>










  <td>0.301</td>










  <td>0.380</td>










  <td>0.391</td>










  <td>0.061</td>










  <td>0.231</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>GeoDesc (8k, NN)</td>










  <td>0.417</td>










  <td>0.647</td>










  <td>0.674</td>










  <td>0.470</td>










  <td>0.714</td>










  <td>0.491</td>










  <td>0.414</td>










  <td>0.463</td>










  <td>0.774</td>










  <td>0.623</td>










  <td>0.162</td>










  <td>0.532</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>HardNet (8k, NN)</td>










  <td>0.409</td>










  <td>0.644</td>










  <td>0.773</td>










  <td>0.470</td>










  <td>0.695</td>










  <td>0.511</td>










  <td>0.461</td>










  <td>0.448</td>










  <td>0.803</td>










  <td>0.638</td>










  <td>0.179</td>










  <td>0.548</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>L2-Net (8k, NN)</td>










  <td>0.329</td>










  <td>0.594</td>










  <td>0.711</td>










  <td>0.438</td>










  <td>0.709</td>










  <td>0.467</td>










  <td>0.400</td>










  <td>0.419</td>










  <td>0.768</td>










  <td>0.583</td>










  <td>0.178</td>










  <td>0.509</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>SIFT (8k, NN)</td>










  <td>0.271</td>










  <td>0.553</td>










  <td>0.477</td>










  <td>0.386</td>










  <td>0.643</td>










  <td>0.318</td>










  <td>0.280</td>










  <td>0.422</td>










  <td>0.600</td>










  <td>0.498</td>










  <td>0.113</td>










  <td>0.415</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>TFeat (8k, NN)</td>










  <td>0.330</td>










  <td>0.531</td>










  <td>0.624</td>










  <td>0.413</td>










  <td>0.682</td>










  <td>0.402</td>










  <td>0.356</td>










  <td>0.393</td>










  <td>0.686</td>










  <td>0.550</td>










  <td>0.140</td>










  <td>0.464</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>SuperPoint</td>










  <td>0.376</td>










  <td>0.393</td>










  <td>0.636</td>










  <td>0.594</td>










  <td>0.505</td>










  <td>0.357</td>










  <td>0.316</td>










  <td>0.372</td>










  <td>0.485</td>










  <td>0.513</td>










  <td>0.147</td>










  <td>0.427</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>




<tr>
  
  <td>SURF (8k, NN)</td>










  <td>0.146</td>










  <td>0.352</td>










  <td>0.386</td>










  <td>0.221</td>










  <td>0.450</td>










  <td>0.213</td>










  <td>0.207</td>










  <td>0.344</td>










  <td>0.498</td>










  <td>0.416</td>










  <td>0.076</td>










  <td>0.301</td>

  
  <td class="hidden_value">2019-04-24</td>
  <td class="hidden_value">F</td>
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>


</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;british_museum&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.2</td>
  <td>3084.3</td>
  <td>99.5</td>
  <td>3.31</td>
  <td>0.099</td>
  <td>0.208</td>
  <td>0.299</td>
  <td>0.370</td>
  <td>0.434</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.6</td>
  <td>2051.6</td>
  <td>94.0</td>
  <td>3.13</td>
  <td>0.024</td>
  <td>0.068</td>
  <td>0.129</td>
  <td>0.194</td>
  <td>0.261</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.6</td>
  <td>3157.8</td>
  <td>100.0</td>
  <td>3.21</td>
  <td>0.157</td>
  <td>0.275</td>
  <td>0.361</td>
  <td>0.443</td>
  <td>0.505</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.8</td>
  <td>3933.0</td>
  <td>100.0</td>
  <td>3.12</td>
  <td>0.168</td>
  <td>0.289</td>
  <td>0.366</td>
  <td>0.460</td>
  <td>0.524</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.7</td>
  <td>3298.0</td>
  <td>100.0</td>
  <td>3.03</td>
  <td>0.107</td>
  <td>0.195</td>
  <td>0.270</td>
  <td>0.347</td>
  <td>0.419</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.1</td>
  <td>2095.8</td>
  <td>97.2</td>
  <td>3.00</td>
  <td>0.074</td>
  <td>0.146</td>
  <td>0.210</td>
  <td>0.282</td>
  <td>0.356</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.3</td>
  <td>2997.1</td>
  <td>99.5</td>
  <td>2.99</td>
  <td>0.104</td>
  <td>0.191</td>
  <td>0.273</td>
  <td>0.351</td>
  <td>0.426</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>81.4</td>
  <td>571.5</td>
  <td>93.5</td>
  <td>3.09</td>
  <td>0.141</td>
  <td>0.252</td>
  <td>0.340</td>
  <td>0.414</td>
  <td>0.474</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.1</td>
  <td>1445.6</td>
  <td>94.2</td>
  <td>2.69</td>
  <td>0.021</td>
  <td>0.060</td>
  <td>0.105</td>
  <td>0.167</td>
  <td>0.239</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;florence_cathedral_side&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>76.8</td>
  <td>2071.9</td>
  <td>82.0</td>
  <td>2.70</td>
  <td>0.281</td>
  <td>0.336</td>
  <td>0.370</td>
  <td>0.397</td>
  <td>0.423</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>72.2</td>
  <td>1503.5</td>
  <td>71.0</td>
  <td>2.49</td>
  <td>0.132</td>
  <td>0.177</td>
  <td>0.206</td>
  <td>0.231</td>
  <td>0.259</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.4</td>
  <td>4110.7</td>
  <td>95.8</td>
  <td>3.06</td>
  <td>0.486</td>
  <td>0.554</td>
  <td>0.597</td>
  <td>0.635</td>
  <td>0.676</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.8</td>
  <td>4586.4</td>
  <td>96.8</td>
  <td>3.04</td>
  <td>0.496</td>
  <td>0.563</td>
  <td>0.600</td>
  <td>0.634</td>
  <td>0.668</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.0</td>
  <td>3963.5</td>
  <td>96.5</td>
  <td>2.92</td>
  <td>0.421</td>
  <td>0.487</td>
  <td>0.526</td>
  <td>0.562</td>
  <td>0.607</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>81.6</td>
  <td>2901.0</td>
  <td>92.5</td>
  <td>2.92</td>
  <td>0.407</td>
  <td>0.462</td>
  <td>0.494</td>
  <td>0.531</td>
  <td>0.569</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.6</td>
  <td>3271.0</td>
  <td>95.0</td>
  <td>2.85</td>
  <td>0.355</td>
  <td>0.412</td>
  <td>0.461</td>
  <td>0.508</td>
  <td>0.552</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>74.4</td>
  <td>673.2</td>
  <td>80.5</td>
  <td>2.79</td>
  <td>0.220</td>
  <td>0.275</td>
  <td>0.312</td>
  <td>0.346</td>
  <td>0.377</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>72.0</td>
  <td>1147.3</td>
  <td>72.2</td>
  <td>2.48</td>
  <td>0.156</td>
  <td>0.201</td>
  <td>0.232</td>
  <td>0.257</td>
  <td>0.284</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;lincoln_memorial_statue&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.7</td>
  <td>2326.4</td>
  <td>87.5</td>
  <td>2.91</td>
  <td>0.384</td>
  <td>0.460</td>
  <td>0.497</td>
  <td>0.528</td>
  <td>0.550</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.6</td>
  <td>1456.9</td>
  <td>91.8</td>
  <td>3.04</td>
  <td>0.124</td>
  <td>0.174</td>
  <td>0.211</td>
  <td>0.251</td>
  <td>0.289</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.0</td>
  <td>3109.8</td>
  <td>96.8</td>
  <td>3.14</td>
  <td>0.575</td>
  <td>0.625</td>
  <td>0.650</td>
  <td>0.674</td>
  <td>0.691</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.7</td>
  <td>4195.4</td>
  <td>96.8</td>
  <td>3.15</td>
  <td>0.668</td>
  <td>0.739</td>
  <td>0.767</td>
  <td>0.784</td>
  <td>0.801</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.6</td>
  <td>3623.6</td>
  <td>94.2</td>
  <td>3.07</td>
  <td>0.580</td>
  <td>0.655</td>
  <td>0.690</td>
  <td>0.713</td>
  <td>0.734</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.5</td>
  <td>1509.1</td>
  <td>86.8</td>
  <td>2.92</td>
  <td>0.281</td>
  <td>0.342</td>
  <td>0.380</td>
  <td>0.410</td>
  <td>0.437</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.9</td>
  <td>2903.7</td>
  <td>92.2</td>
  <td>2.99</td>
  <td>0.476</td>
  <td>0.544</td>
  <td>0.579</td>
  <td>0.604</td>
  <td>0.630</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.5</td>
  <td>575.2</td>
  <td>87.2</td>
  <td>3.63</td>
  <td>0.523</td>
  <td>0.591</td>
  <td>0.619</td>
  <td>0.639</td>
  <td>0.651</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.4</td>
  <td>1232.0</td>
  <td>85.2</td>
  <td>2.75</td>
  <td>0.173</td>
  <td>0.234</td>
  <td>0.271</td>
  <td>0.305</td>
  <td>0.338</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;london_bridge&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.4</td>
  <td>1677.8</td>
  <td>89.2</td>
  <td>2.92</td>
  <td>0.151</td>
  <td>0.236</td>
  <td>0.289</td>
  <td>0.340</td>
  <td>0.380</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>73.8</td>
  <td>1212.4</td>
  <td>78.2</td>
  <td>2.62</td>
  <td>0.029</td>
  <td>0.066</td>
  <td>0.096</td>
  <td>0.130</td>
  <td>0.162</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.8</td>
  <td>2609.0</td>
  <td>97.0</td>
  <td>3.08</td>
  <td>0.263</td>
  <td>0.367</td>
  <td>0.419</td>
  <td>0.468</td>
  <td>0.504</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.7</td>
  <td>3466.3</td>
  <td>97.5</td>
  <td>3.03</td>
  <td>0.230</td>
  <td>0.336</td>
  <td>0.405</td>
  <td>0.451</td>
  <td>0.489</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.8</td>
  <td>3132.1</td>
  <td>98.2</td>
  <td>3.01</td>
  <td>0.204</td>
  <td>0.292</td>
  <td>0.367</td>
  <td>0.421</td>
  <td>0.468</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.3</td>
  <td>1773.4</td>
  <td>87.8</td>
  <td>2.95</td>
  <td>0.177</td>
  <td>0.259</td>
  <td>0.318</td>
  <td>0.365</td>
  <td>0.410</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.7</td>
  <td>2601.0</td>
  <td>97.0</td>
  <td>3.00</td>
  <td>0.188</td>
  <td>0.290</td>
  <td>0.352</td>
  <td>0.396</td>
  <td>0.438</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.0</td>
  <td>597.5</td>
  <td>92.8</td>
  <td>3.45</td>
  <td>0.377</td>
  <td>0.512</td>
  <td>0.572</td>
  <td>0.614</td>
  <td>0.648</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>77.7</td>
  <td>977.1</td>
  <td>84.2</td>
  <td>2.65</td>
  <td>0.058</td>
  <td>0.117</td>
  <td>0.165</td>
  <td>0.207</td>
  <td>0.250</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;milan_cathedral&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.0</td>
  <td>2697.1</td>
  <td>90.2</td>
  <td>3.10</td>
  <td>0.337</td>
  <td>0.492</td>
  <td>0.565</td>
  <td>0.618</td>
  <td>0.649</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>68.6</td>
  <td>1285.4</td>
  <td>66.5</td>
  <td>2.49</td>
  <td>0.041</td>
  <td>0.083</td>
  <td>0.118</td>
  <td>0.141</td>
  <td>0.163</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.4</td>
  <td>3640.1</td>
  <td>98.2</td>
  <td>3.24</td>
  <td>0.454</td>
  <td>0.620</td>
  <td>0.693</td>
  <td>0.740</td>
  <td>0.768</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.6</td>
  <td>4478.6</td>
  <td>98.5</td>
  <td>3.14</td>
  <td>0.438</td>
  <td>0.599</td>
  <td>0.672</td>
  <td>0.727</td>
  <td>0.761</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.5</td>
  <td>4123.9</td>
  <td>97.8</td>
  <td>3.13</td>
  <td>0.446</td>
  <td>0.606</td>
  <td>0.687</td>
  <td>0.741</td>
  <td>0.771</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.8</td>
  <td>2720.7</td>
  <td>92.0</td>
  <td>3.09</td>
  <td>0.393</td>
  <td>0.531</td>
  <td>0.612</td>
  <td>0.656</td>
  <td>0.683</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.4</td>
  <td>3535.7</td>
  <td>96.5</td>
  <td>3.09</td>
  <td>0.427</td>
  <td>0.591</td>
  <td>0.662</td>
  <td>0.714</td>
  <td>0.752</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.6</td>
  <td>675.7</td>
  <td>85.2</td>
  <td>3.05</td>
  <td>0.250</td>
  <td>0.381</td>
  <td>0.455</td>
  <td>0.510</td>
  <td>0.540</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>77.6</td>
  <td>1341.1</td>
  <td>82.5</td>
  <td>2.80</td>
  <td>0.197</td>
  <td>0.311</td>
  <td>0.374</td>
  <td>0.418</td>
  <td>0.448</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;mount_rushmore&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>73.1</td>
  <td>1203.9</td>
  <td>84.5</td>
  <td>2.85</td>
  <td>0.084</td>
  <td>0.143</td>
  <td>0.198</td>
  <td>0.250</td>
  <td>0.293</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>65.8</td>
  <td>997.9</td>
  <td>69.8</td>
  <td>2.60</td>
  <td>0.022</td>
  <td>0.051</td>
  <td>0.078</td>
  <td>0.106</td>
  <td>0.128</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>78.0</td>
  <td>2049.4</td>
  <td>91.2</td>
  <td>3.06</td>
  <td>0.229</td>
  <td>0.329</td>
  <td>0.391</td>
  <td>0.450</td>
  <td>0.487</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.9</td>
  <td>2638.3</td>
  <td>91.8</td>
  <td>3.10</td>
  <td>0.242</td>
  <td>0.367</td>
  <td>0.442</td>
  <td>0.503</td>
  <td>0.547</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>77.5</td>
  <td>2119.3</td>
  <td>89.5</td>
  <td>2.98</td>
  <td>0.204</td>
  <td>0.303</td>
  <td>0.378</td>
  <td>0.436</td>
  <td>0.481</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>69.9</td>
  <td>1018.0</td>
  <td>83.0</td>
  <td>2.69</td>
  <td>0.082</td>
  <td>0.146</td>
  <td>0.197</td>
  <td>0.242</td>
  <td>0.274</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>75.4</td>
  <td>1469.4</td>
  <td>86.8</td>
  <td>2.87</td>
  <td>0.140</td>
  <td>0.218</td>
  <td>0.287</td>
  <td>0.340</td>
  <td>0.379</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>75.2</td>
  <td>307.3</td>
  <td>87.8</td>
  <td>3.28</td>
  <td>0.114</td>
  <td>0.202</td>
  <td>0.267</td>
  <td>0.320</td>
  <td>0.367</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>68.9</td>
  <td>730.8</td>
  <td>76.5</td>
  <td>2.68</td>
  <td>0.026</td>
  <td>0.062</td>
  <td>0.099</td>
  <td>0.135</td>
  <td>0.167</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;piazza_san_marco&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>75.1</td>
  <td>2125.4</td>
  <td>84.8</td>
  <td>2.22</td>
  <td>0.057</td>
  <td>0.132</td>
  <td>0.194</td>
  <td>0.247</td>
  <td>0.290</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>73.0</td>
  <td>1957.1</td>
  <td>86.8</td>
  <td>2.13</td>
  <td>0.015</td>
  <td>0.057</td>
  <td>0.116</td>
  <td>0.167</td>
  <td>0.220</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.7</td>
  <td>3170.0</td>
  <td>94.8</td>
  <td>2.35</td>
  <td>0.149</td>
  <td>0.253</td>
  <td>0.324</td>
  <td>0.385</td>
  <td>0.442</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.7</td>
  <td>3874.7</td>
  <td>99.2</td>
  <td>2.37</td>
  <td>0.181</td>
  <td>0.293</td>
  <td>0.379</td>
  <td>0.443</td>
  <td>0.490</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.5</td>
  <td>3198.7</td>
  <td>97.2</td>
  <td>2.30</td>
  <td>0.127</td>
  <td>0.229</td>
  <td>0.310</td>
  <td>0.372</td>
  <td>0.420</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>76.4</td>
  <td>2067.5</td>
  <td>87.2</td>
  <td>2.22</td>
  <td>0.074</td>
  <td>0.151</td>
  <td>0.215</td>
  <td>0.272</td>
  <td>0.307</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>81.2</td>
  <td>2921.5</td>
  <td>95.0</td>
  <td>2.26</td>
  <td>0.097</td>
  <td>0.203</td>
  <td>0.288</td>
  <td>0.361</td>
  <td>0.422</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>71.7</td>
  <td>577.4</td>
  <td>80.2</td>
  <td>2.30</td>
  <td>0.080</td>
  <td>0.172</td>
  <td>0.237</td>
  <td>0.280</td>
  <td>0.317</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>67.2</td>
  <td>1300.3</td>
  <td>74.5</td>
  <td>2.15</td>
  <td>0.036</td>
  <td>0.090</td>
  <td>0.135</td>
  <td>0.168</td>
  <td>0.199</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;reichstag&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.2</td>
  <td>1854.7</td>
  <td>90.3</td>
  <td>3.07</td>
  <td>0.206</td>
  <td>0.309</td>
  <td>0.388</td>
  <td>0.449</td>
  <td>0.495</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>72.5</td>
  <td>1064.4</td>
  <td>83.0</td>
  <td>2.56</td>
  <td>0.066</td>
  <td>0.138</td>
  <td>0.196</td>
  <td>0.245</td>
  <td>0.283</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.0</td>
  <td>3077.6</td>
  <td>96.8</td>
  <td>3.01</td>
  <td>0.206</td>
  <td>0.305</td>
  <td>0.380</td>
  <td>0.440</td>
  <td>0.478</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.6</td>
  <td>3646.3</td>
  <td>98.2</td>
  <td>2.95</td>
  <td>0.188</td>
  <td>0.296</td>
  <td>0.371</td>
  <td>0.423</td>
  <td>0.473</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.5</td>
  <td>3267.3</td>
  <td>98.8</td>
  <td>2.91</td>
  <td>0.147</td>
  <td>0.270</td>
  <td>0.344</td>
  <td>0.394</td>
  <td>0.439</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.9</td>
  <td>2064.7</td>
  <td>92.2</td>
  <td>2.92</td>
  <td>0.166</td>
  <td>0.263</td>
  <td>0.339</td>
  <td>0.395</td>
  <td>0.441</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>81.8</td>
  <td>2873.8</td>
  <td>97.0</td>
  <td>2.87</td>
  <td>0.152</td>
  <td>0.260</td>
  <td>0.333</td>
  <td>0.391</td>
  <td>0.431</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>78.1</td>
  <td>642.6</td>
  <td>92.8</td>
  <td>3.08</td>
  <td>0.143</td>
  <td>0.255</td>
  <td>0.315</td>
  <td>0.365</td>
  <td>0.400</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>75.5</td>
  <td>930.5</td>
  <td>87.2</td>
  <td>2.77</td>
  <td>0.123</td>
  <td>0.203</td>
  <td>0.262</td>
  <td>0.307</td>
  <td>0.342</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;sagrada_familia&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.6</td>
  <td>3153.9</td>
  <td>86.0</td>
  <td>2.92</td>
  <td>0.435</td>
  <td>0.500</td>
  <td>0.526</td>
  <td>0.546</td>
  <td>0.565</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>75.1</td>
  <td>2106.8</td>
  <td>77.8</td>
  <td>2.65</td>
  <td>0.209</td>
  <td>0.270</td>
  <td>0.301</td>
  <td>0.324</td>
  <td>0.346</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.8</td>
  <td>4474.6</td>
  <td>95.8</td>
  <td>3.28</td>
  <td>0.668</td>
  <td>0.738</td>
  <td>0.760</td>
  <td>0.781</td>
  <td>0.797</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.4</td>
  <td>5248.8</td>
  <td>98.5</td>
  <td>3.22</td>
  <td>0.686</td>
  <td>0.761</td>
  <td>0.791</td>
  <td>0.807</td>
  <td>0.825</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.8</td>
  <td>4737.2</td>
  <td>96.2</td>
  <td>3.15</td>
  <td>0.641</td>
  <td>0.719</td>
  <td>0.748</td>
  <td>0.766</td>
  <td>0.784</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>80.3</td>
  <td>3243.2</td>
  <td>85.5</td>
  <td>2.98</td>
  <td>0.481</td>
  <td>0.540</td>
  <td>0.565</td>
  <td>0.582</td>
  <td>0.598</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>82.5</td>
  <td>4145.7</td>
  <td>92.2</td>
  <td>3.09</td>
  <td>0.573</td>
  <td>0.641</td>
  <td>0.670</td>
  <td>0.690</td>
  <td>0.709</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>74.3</td>
  <td>852.5</td>
  <td>81.0</td>
  <td>2.99</td>
  <td>0.369</td>
  <td>0.428</td>
  <td>0.452</td>
  <td>0.466</td>
  <td>0.477</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>76.0</td>
  <td>1959.3</td>
  <td>79.0</td>
  <td>2.77</td>
  <td>0.336</td>
  <td>0.398</td>
  <td>0.429</td>
  <td>0.443</td>
  <td>0.457</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;st_pauls_cathedral&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.1</td>
  <td>2775.9</td>
  <td>93.0</td>
  <td>2.92</td>
  <td>0.360</td>
  <td>0.482</td>
  <td>0.563</td>
  <td>0.612</td>
  <td>0.652</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>76.5</td>
  <td>1529.4</td>
  <td>76.8</td>
  <td>2.56</td>
  <td>0.143</td>
  <td>0.230</td>
  <td>0.279</td>
  <td>0.321</td>
  <td>0.360</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.2</td>
  <td>3728.9</td>
  <td>97.2</td>
  <td>3.00</td>
  <td>0.360</td>
  <td>0.499</td>
  <td>0.581</td>
  <td>0.647</td>
  <td>0.692</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.6</td>
  <td>4466.8</td>
  <td>98.2</td>
  <td>3.01</td>
  <td>0.378</td>
  <td>0.510</td>
  <td>0.590</td>
  <td>0.646</td>
  <td>0.685</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>84.3</td>
  <td>3994.3</td>
  <td>98.2</td>
  <td>2.85</td>
  <td>0.273</td>
  <td>0.419</td>
  <td>0.526</td>
  <td>0.586</td>
  <td>0.643</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>81.2</td>
  <td>2354.3</td>
  <td>89.8</td>
  <td>2.72</td>
  <td>0.213</td>
  <td>0.339</td>
  <td>0.420</td>
  <td>0.468</td>
  <td>0.522</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>83.9</td>
  <td>3466.5</td>
  <td>96.5</td>
  <td>2.79</td>
  <td>0.249</td>
  <td>0.399</td>
  <td>0.492</td>
  <td>0.564</td>
  <td>0.610</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.1</td>
  <td>631.7</td>
  <td>88.5</td>
  <td>3.03</td>
  <td>0.271</td>
  <td>0.394</td>
  <td>0.460</td>
  <td>0.511</td>
  <td>0.551</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>76.8</td>
  <td>1204.0</td>
  <td>80.2</td>
  <td>2.60</td>
  <td>0.141</td>
  <td>0.252</td>
  <td>0.320</td>
  <td>0.367</td>
  <td>0.408</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>



<hr>










<table class="display leaderboard_mvs" width="100%" cellspacing="0">
<thead>
<tr>
  <th colspan="13" style="text-align: center;" class="sorter-false">MVS &mdash; sequence &#39;united_states_capitol&#39;</th>
</tr>
<tr>
  
  <th class="all">Method</th>
  <th class="all">Date</th>
  <th class="all">Type</th>
  
  <th class="all">Ims (%)</th>
  <th class="all">#Pts</th>
  <th class="all">SR</th>
  <th class="all">TL</th>
  <th class="all">mAP<sup>5<sup>o</sup></sup></th>
  <th class="all">mAP<sup>10<sup>o</sup></sup></th>
  <th class="all">mAP<sup>15<sup>o</sup></sup></th>
  <th class="all">mAP<sup>20<sup>o</sup></sup></th>
  <th class="all">mAP<sup>25<sup>o</sup></sup></th>
  <th class="all">ATE</th>
  
  <th class="none hidden_key">By</th>
  <th class="none hidden_key">Details</th>
  <th class="none hidden_key">Link</th>
  <th class="none hidden_key">Contact</th>
  <th class="none hidden_key">Updated</th>
</tr>
</thead>
<tbody>































<tr>
  
  <td>AKAZE (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>77.0</td>
  <td>828.8</td>
  <td>86.5</td>
  <td>2.53</td>
  <td>0.025</td>
  <td>0.071</td>
  <td>0.124</td>
  <td>0.183</td>
  <td>0.231</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">AKAZE, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>ORB (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>60.4</td>
  <td>586.0</td>
  <td>57.8</td>
  <td>2.24</td>
  <td>0.004</td>
  <td>0.017</td>
  <td>0.031</td>
  <td>0.045</td>
  <td>0.058</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">ORB, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>GeoDesc (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>78.0</td>
  <td>906.3</td>
  <td>90.2</td>
  <td>2.52</td>
  <td>0.028</td>
  <td>0.069</td>
  <td>0.121</td>
  <td>0.188</td>
  <td>0.239</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">GeoDesc extracted on SIFT keypoints. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/lzx551402/geodesc">https://github.com/lzx551402/geodesc</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>HardNet (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>79.7</td>
  <td>1139.8</td>
  <td>93.5</td>
  <td>2.54</td>
  <td>0.027</td>
  <td>0.073</td>
  <td>0.137</td>
  <td>0.197</td>
  <td>0.258</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">HardNet extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/DagnyT/hardnet">https://github.com/DagnyT/hardnet</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>L2-Net (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>78.2</td>
  <td>985.4</td>
  <td>93.0</td>
  <td>2.54</td>
  <td>0.027</td>
  <td>0.073</td>
  <td>0.129</td>
  <td>0.197</td>
  <td>0.254</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">L2-Net extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/yuruntian/L2-Net">https://github.com/yuruntian/L2-Net</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SIFT (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>68.7</td>
  <td>548.1</td>
  <td>79.8</td>
  <td>2.37</td>
  <td>0.009</td>
  <td>0.031</td>
  <td>0.063</td>
  <td>0.095</td>
  <td>0.125</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SIFT, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>TFeat (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>77.4</td>
  <td>896.5</td>
  <td>87.8</td>
  <td>2.45</td>
  <td>0.015</td>
  <td>0.057</td>
  <td>0.106</td>
  <td>0.166</td>
  <td>0.219</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">T-Feat extracted on SIFT keypoints. Number of keypoints: 8000 per image. Models trained on the Liberty sequence of the Brown dataset. We use slightly larger paches than specified for SIFT (scale multiplying factor 16/12). Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/vbalnt/tfeat">https://github.com/vbalnt/tfeat</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SuperPoint</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>69.0</td>
  <td>171.6</td>
  <td>75.0</td>
  <td>2.61</td>
  <td>0.017</td>
  <td>0.049</td>
  <td>0.085</td>
  <td>0.123</td>
  <td>0.164</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SuperPoint features. If necessary, we downsample the images so that the largest dimension is at most 1024 pixels, and use as many keypoints as the model returns. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://github.com/rpautrat/SuperPoint">https://github.com/rpautrat/SuperPoint</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  































<tr>
  
  <td>SURF (8k, NN)</td>
  <td data-sorter="shortDate" data-date-format="yyyymmdd">2019-04-24</td>
  <td>F</td>
  
  <td>69.4</td>
  <td>478.4</td>
  <td>73.0</td>
  <td>2.30</td>
  <td>0.005</td>
  <td>0.021</td>
  <td>0.049</td>
  <td>0.085</td>
  <td>0.113</td>
  
  <td>&mdash;</td>
  
  <td class="hidden_value">Challenge organizers</td>
  <td class="hidden_value">SURF, as implemented in OpenCV. Number of keypoints: 8000 per image. Feature matching with brute-force nearest-neighbour search.</td>
  <td class="hidden_value"><a href="https://opencv.org">https://opencv.org</a></td>
  <td class="hidden_value"><a href="mailto:imagematching@uvic.ca">imagematching@uvic.ca</a></td>
  <td class="hidden_value">N/A</td>
</tr>
  

</tbody>
</table>


</p>

<h3 id="a-name-glossary-a-glossary"><a name="glossary"></a>Glossary</h3>

Multi-view reconstruction task:

<ul>
  <li><b>Type:</b> Input format. "F": Features. "M": Features and matches. "P": Poses.</li>
  <li><b>#Ims:</b> Ratio of images registered by the reconstruction (on successful reconstructions).</li>
  <li><b>#Pts:</b> Average number of 3D points obtained by the reconstruction.</li>
  <li><b>SR:</b> Success ratio (percentage) in the re-construction with COLMAP, out of 100 subsets.</li>
  <li><b>TL:</b> Average track length (number of 3D point observations).</li>
  <li><b>mAP<sup>x</sup>:</b> Mean average precision at angular threshold *x*.</li>
  <li><b>ATE:</b> Absolute Trajectory Error.</li>
</ul>


  </div>
</section>
<section id="tag-pane" class="row meta">
  
</section>








<section id="menu-pane" class="row menu text-center">
  
  
  <span><a class="menu-item" href="https://image-matching-workshop.github.io/breakdown/phototourism/mvs/by_bag/">&lt; prev | </a></span>
  
  
  <span><a class="menu-item" href="/breakdown">breakdown</a></span>
  
  
  
  <h4 class="text-center"><a class="menu-item" href="https://image-matching-workshop.github.io/">home</a></h4>
</section>



<footer class="row text-center footer">
  
  
</footer>

</div>




<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-62863910-6', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="js/main.js"></script>

</script>
</body>
</html>


